{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1b3bb11-fc06-4550-9ace-5188c3a78199",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run center_of_mass_calculation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb88468c-b1b1-49f5-9029-dab66a866109",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 3phase_pm_engine_simulation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d9b64c-b0d4-4841-a384-8df3cf9d5894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b33633c8-bdf5-44c1-a602-5e02c80ee655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"full_df.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e26007-796b-407d-9e48-42d9cdd6fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d7e6d1-7e05-411b-bfe7-d461b09e14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, :29]\n",
    "y = data[:, 29:] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15535f1-2efd-4b58-b154-7b2dca72cf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a06bc5-d7c5-43f2-aa43-8ce43cb422f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.constant(X_train, dtype=\"float32\")\n",
    "X_test = tf.constant(X_test, dtype=\"float32\")\n",
    "y_train = tf.constant(y_train, dtype=\"float32\")\n",
    "y_test = tf.constant(y_test, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89da2599-ce05-4aeb-aea9-accaf7cae123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([41783, 29])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a458d8f4-7eb8-4d97-a0f9-603b25828acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(100_000).batch(256)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "605bdcfb-f97d-4468-ab3e-3c5cba3c865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hundred_relu(x):\n",
    "    return K.relu(x, max_value=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "475c15a1-130a-4ab6-ae26-b6aa62080bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluatorNetwork(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layers = [\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        ]\n",
    "        self.output_layer = tf.keras.layers.Dense(1, activation=hundred_relu)\n",
    "        \n",
    "    def call(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b39b25c7-edb8-4df3-939a-44c8c4e8bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = EvaluatorNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3587a0b-2654-46bf-bb6a-a37691bca525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"evaluator_network_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_1 (Batc  multiple                 116       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  1920      \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  4160      \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  4160      \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,421\n",
      "Trainable params: 10,363\n",
      "Non-trainable params: 58\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "evaluator.build(input_shape=(None, 29))\n",
    "evaluator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0626a761-20ab-4fc3-be54-a74fee7f3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanAbsoluteError()\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a34e38c6-cc5e-4d47-a63b-43e994e4c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd39eaba-7dda-4278-a7b3-9fc5367a1f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def evaluator_train_step(params, perf):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = evaluator(params, training=True)\n",
    "        loss = loss_object(perf, predictions)\n",
    "    gradients = tape.gradient(loss, evaluator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, evaluator.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1371a4f-4caf-48a8-8b50-d05e8e7ebbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def evaluator_test_step(params, perf):\n",
    "    predictions = evaluator(params, training=False)\n",
    "    t_loss = loss_object(perf, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "886e876a-57f4-44f5-ae05-d90fa1bd2b08",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 48.87505340576172, Test Loss: 41.092647552490234, \n",
      "Epoch 2, Loss: 29.679698944091797, Test Loss: 10.80240535736084, \n",
      "Epoch 3, Loss: 8.67816162109375, Test Loss: 7.029417991638184, \n",
      "Epoch 4, Loss: 6.384271621704102, Test Loss: 5.968738079071045, \n",
      "Epoch 5, Loss: 5.7814130783081055, Test Loss: 5.644043922424316, \n",
      "Epoch 6, Loss: 5.554055690765381, Test Loss: 5.46052885055542, \n",
      "Epoch 7, Loss: 5.395282745361328, Test Loss: 5.315282344818115, \n",
      "Epoch 8, Loss: 5.242210388183594, Test Loss: 5.188177585601807, \n",
      "Epoch 9, Loss: 5.117482662200928, Test Loss: 5.070277214050293, \n",
      "Epoch 10, Loss: 5.0027642250061035, Test Loss: 4.964953899383545, \n",
      "Epoch 11, Loss: 4.881549835205078, Test Loss: 4.868453025817871, \n",
      "Epoch 12, Loss: 4.801510334014893, Test Loss: 4.777055263519287, \n",
      "Epoch 13, Loss: 4.702637195587158, Test Loss: 4.691908359527588, \n",
      "Epoch 14, Loss: 4.6196699142456055, Test Loss: 4.613702297210693, \n",
      "Epoch 15, Loss: 4.538541316986084, Test Loss: 4.543344974517822, \n",
      "Epoch 16, Loss: 4.458109378814697, Test Loss: 4.475435256958008, \n",
      "Epoch 17, Loss: 4.40144681930542, Test Loss: 4.416706562042236, \n",
      "Epoch 18, Loss: 4.329923152923584, Test Loss: 4.352839469909668, \n",
      "Epoch 19, Loss: 4.26188850402832, Test Loss: 4.295125484466553, \n",
      "Epoch 20, Loss: 4.202531337738037, Test Loss: 4.242365837097168, \n",
      "Epoch 21, Loss: 4.150224685668945, Test Loss: 4.192318439483643, \n",
      "Epoch 22, Loss: 4.096185684204102, Test Loss: 4.141513347625732, \n",
      "Epoch 23, Loss: 4.046009540557861, Test Loss: 4.097253799438477, \n",
      "Epoch 24, Loss: 4.012713432312012, Test Loss: 4.0585455894470215, \n",
      "Epoch 25, Loss: 3.963632345199585, Test Loss: 4.017466068267822, \n",
      "Epoch 26, Loss: 3.9237217903137207, Test Loss: 3.9740564823150635, \n",
      "Epoch 27, Loss: 3.8810927867889404, Test Loss: 3.9347636699676514, \n",
      "Epoch 28, Loss: 3.8473923206329346, Test Loss: 3.899014472961426, \n",
      "Epoch 29, Loss: 3.799619674682617, Test Loss: 3.861368417739868, \n",
      "Epoch 30, Loss: 3.77211332321167, Test Loss: 3.8292369842529297, \n",
      "Epoch 31, Loss: 3.7409496307373047, Test Loss: 3.7973217964172363, \n",
      "Epoch 32, Loss: 3.7032406330108643, Test Loss: 3.767937421798706, \n",
      "Epoch 33, Loss: 3.6807005405426025, Test Loss: 3.736574411392212, \n",
      "Epoch 34, Loss: 3.641050338745117, Test Loss: 3.7128169536590576, \n",
      "Epoch 35, Loss: 3.615389823913574, Test Loss: 3.685795307159424, \n",
      "Epoch 36, Loss: 3.5908567905426025, Test Loss: 3.6607019901275635, \n",
      "Epoch 37, Loss: 3.566560745239258, Test Loss: 3.641011953353882, \n",
      "Epoch 38, Loss: 3.5514447689056396, Test Loss: 3.6106505393981934, \n",
      "Epoch 39, Loss: 3.519317626953125, Test Loss: 3.5871691703796387, \n",
      "Epoch 40, Loss: 3.49326491355896, Test Loss: 3.5743658542633057, \n",
      "Epoch 41, Loss: 3.4792797565460205, Test Loss: 3.5444986820220947, \n",
      "Epoch 42, Loss: 3.451768398284912, Test Loss: 3.5262320041656494, \n",
      "Epoch 43, Loss: 3.4365055561065674, Test Loss: 3.506410837173462, \n",
      "Epoch 44, Loss: 3.4219253063201904, Test Loss: 3.484635591506958, \n",
      "Epoch 45, Loss: 3.3921024799346924, Test Loss: 3.469882011413574, \n",
      "Epoch 46, Loss: 3.377235174179077, Test Loss: 3.454832077026367, \n",
      "Epoch 47, Loss: 3.363370895385742, Test Loss: 3.437525510787964, \n",
      "Epoch 48, Loss: 3.3556735515594482, Test Loss: 3.429651975631714, \n",
      "Epoch 49, Loss: 3.337575674057007, Test Loss: 3.406616687774658, \n",
      "Epoch 50, Loss: 3.321566343307495, Test Loss: 3.394580364227295, \n",
      "Epoch 51, Loss: 3.304605722427368, Test Loss: 3.381960868835449, \n",
      "Epoch 52, Loss: 3.29819917678833, Test Loss: 3.388578414916992, \n",
      "Epoch 53, Loss: 3.2792015075683594, Test Loss: 3.355441093444824, \n",
      "Epoch 54, Loss: 3.2739830017089844, Test Loss: 3.342890739440918, \n",
      "Epoch 55, Loss: 3.2516705989837646, Test Loss: 3.3301432132720947, \n",
      "Epoch 56, Loss: 3.242011070251465, Test Loss: 3.322911500930786, \n",
      "Epoch 57, Loss: 3.235997200012207, Test Loss: 3.321873903274536, \n",
      "Epoch 58, Loss: 3.237464427947998, Test Loss: 3.301100492477417, \n",
      "Epoch 59, Loss: 3.21492600440979, Test Loss: 3.297563076019287, \n",
      "Epoch 60, Loss: 3.202479600906372, Test Loss: 3.286012887954712, \n",
      "Epoch 61, Loss: 3.194277763366699, Test Loss: 3.273433208465576, \n",
      "Epoch 62, Loss: 3.1967051029205322, Test Loss: 3.273676633834839, \n",
      "Epoch 63, Loss: 3.18345046043396, Test Loss: 3.2574989795684814, \n",
      "Epoch 64, Loss: 3.1728880405426025, Test Loss: 3.250046491622925, \n",
      "Epoch 65, Loss: 3.1651902198791504, Test Loss: 3.2451930046081543, \n",
      "Epoch 66, Loss: 3.1562280654907227, Test Loss: 3.233374834060669, \n",
      "Epoch 67, Loss: 3.1483700275421143, Test Loss: 3.230799436569214, \n",
      "Epoch 68, Loss: 3.141169786453247, Test Loss: 3.222200632095337, \n",
      "Epoch 69, Loss: 3.1387150287628174, Test Loss: 3.2148826122283936, \n",
      "Epoch 70, Loss: 3.132628917694092, Test Loss: 3.2122392654418945, \n",
      "Epoch 71, Loss: 3.1280956268310547, Test Loss: 3.2015514373779297, \n",
      "Epoch 72, Loss: 3.1191461086273193, Test Loss: 3.1970956325531006, \n",
      "Epoch 73, Loss: 3.1119067668914795, Test Loss: 3.1935343742370605, \n",
      "Epoch 74, Loss: 3.1107237339019775, Test Loss: 3.187303066253662, \n",
      "Epoch 75, Loss: 3.1005802154541016, Test Loss: 3.184342622756958, \n",
      "Epoch 76, Loss: 3.0999062061309814, Test Loss: 3.1800668239593506, \n",
      "Epoch 77, Loss: 3.0955865383148193, Test Loss: 3.180546283721924, \n",
      "Epoch 78, Loss: 3.096216917037964, Test Loss: 3.1916677951812744, \n",
      "Epoch 79, Loss: 3.0846846103668213, Test Loss: 3.169480085372925, \n",
      "Epoch 80, Loss: 3.078322649002075, Test Loss: 3.1616177558898926, \n",
      "Epoch 81, Loss: 3.079122304916382, Test Loss: 3.1580593585968018, \n",
      "Epoch 82, Loss: 3.0773415565490723, Test Loss: 3.1695902347564697, \n",
      "Epoch 83, Loss: 3.0781242847442627, Test Loss: 3.1574032306671143, \n",
      "Epoch 84, Loss: 3.0690107345581055, Test Loss: 3.1514194011688232, \n",
      "Epoch 85, Loss: 3.0626137256622314, Test Loss: 3.1434922218322754, \n",
      "Epoch 86, Loss: 3.061765432357788, Test Loss: 3.1431081295013428, \n",
      "Epoch 87, Loss: 3.0599634647369385, Test Loss: 3.13932728767395, \n",
      "Epoch 88, Loss: 3.0617120265960693, Test Loss: 3.1339526176452637, \n",
      "Epoch 89, Loss: 3.052605152130127, Test Loss: 3.1322290897369385, \n",
      "Epoch 90, Loss: 3.0523509979248047, Test Loss: 3.1372735500335693, \n",
      "Epoch 91, Loss: 3.041454315185547, Test Loss: 3.1283082962036133, \n",
      "Epoch 92, Loss: 3.0422680377960205, Test Loss: 3.1302976608276367, \n",
      "Epoch 93, Loss: 3.0384902954101562, Test Loss: 3.1358449459075928, \n",
      "Epoch 94, Loss: 3.043508291244507, Test Loss: 3.1316914558410645, \n",
      "Epoch 95, Loss: 3.032227039337158, Test Loss: 3.1202232837677, \n",
      "Epoch 96, Loss: 3.0386438369750977, Test Loss: 3.120603322982788, \n",
      "Epoch 97, Loss: 3.0299482345581055, Test Loss: 3.118459701538086, \n",
      "Epoch 98, Loss: 3.032768964767456, Test Loss: 3.116140365600586, \n",
      "Epoch 99, Loss: 3.02825927734375, Test Loss: 3.110140562057495, \n",
      "Epoch 100, Loss: 3.0263564586639404, Test Loss: 3.1152169704437256, \n",
      "Epoch 101, Loss: 3.0250749588012695, Test Loss: 3.1071341037750244, \n",
      "Epoch 102, Loss: 3.0302891731262207, Test Loss: 3.1087534427642822, \n",
      "Epoch 103, Loss: 3.0200612545013428, Test Loss: 3.1030454635620117, \n",
      "Epoch 104, Loss: 3.0199317932128906, Test Loss: 3.104917287826538, \n",
      "Epoch 105, Loss: 3.0158190727233887, Test Loss: 3.101335048675537, \n",
      "Epoch 106, Loss: 3.0103840827941895, Test Loss: 3.1000239849090576, \n",
      "Epoch 107, Loss: 3.0132315158843994, Test Loss: 3.098843812942505, \n",
      "Epoch 108, Loss: 3.0053551197052, Test Loss: 3.099256992340088, \n",
      "Epoch 109, Loss: 3.004000663757324, Test Loss: 3.0942320823669434, \n",
      "Epoch 110, Loss: 3.0026843547821045, Test Loss: 3.101532459259033, \n",
      "Epoch 111, Loss: 3.001326322555542, Test Loss: 3.0914034843444824, \n",
      "Epoch 112, Loss: 3.0042903423309326, Test Loss: 3.0913875102996826, \n",
      "Epoch 113, Loss: 3.002351999282837, Test Loss: 3.089395761489868, \n",
      "Epoch 114, Loss: 3.0031166076660156, Test Loss: 3.089052438735962, \n",
      "Epoch 115, Loss: 2.9948995113372803, Test Loss: 3.0860395431518555, \n",
      "Epoch 116, Loss: 2.9903464317321777, Test Loss: 3.092107057571411, \n",
      "Epoch 117, Loss: 2.9931063652038574, Test Loss: 3.0907039642333984, \n",
      "Epoch 118, Loss: 2.9930152893066406, Test Loss: 3.093167304992676, \n",
      "Epoch 119, Loss: 2.9872944355010986, Test Loss: 3.08211088180542, \n",
      "Epoch 120, Loss: 2.9968600273132324, Test Loss: 3.086205244064331, \n",
      "Epoch 121, Loss: 2.9837753772735596, Test Loss: 3.082364082336426, \n",
      "Epoch 122, Loss: 2.9853649139404297, Test Loss: 3.0789096355438232, \n",
      "Epoch 123, Loss: 2.9796648025512695, Test Loss: 3.089548349380493, \n",
      "Epoch 124, Loss: 2.9764933586120605, Test Loss: 3.079789400100708, \n",
      "Epoch 125, Loss: 2.9831314086914062, Test Loss: 3.077249765396118, \n",
      "Epoch 126, Loss: 2.977303981781006, Test Loss: 3.08528208732605, \n",
      "Epoch 127, Loss: 2.978360414505005, Test Loss: 3.0826685428619385, \n",
      "Epoch 128, Loss: 2.9746925830841064, Test Loss: 3.0798451900482178, \n",
      "Epoch 129, Loss: 2.9726693630218506, Test Loss: 3.0777974128723145, \n",
      "Epoch 130, Loss: 2.9767487049102783, Test Loss: 3.071920871734619, \n",
      "Epoch 131, Loss: 2.9728856086730957, Test Loss: 3.0734241008758545, \n",
      "Epoch 132, Loss: 2.9689443111419678, Test Loss: 3.070992946624756, \n",
      "Epoch 133, Loss: 2.970252513885498, Test Loss: 3.068662643432617, \n",
      "Epoch 134, Loss: 2.967211961746216, Test Loss: 3.07195782661438, \n",
      "Epoch 135, Loss: 2.968562126159668, Test Loss: 3.0694918632507324, \n",
      "Epoch 136, Loss: 2.9640309810638428, Test Loss: 3.0918502807617188, \n",
      "Epoch 137, Loss: 2.964038848876953, Test Loss: 3.076885461807251, \n",
      "Epoch 138, Loss: 2.9602298736572266, Test Loss: 3.0638821125030518, \n",
      "Epoch 139, Loss: 2.9738152027130127, Test Loss: 3.0629329681396484, \n",
      "Epoch 140, Loss: 2.959486484527588, Test Loss: 3.0634031295776367, \n",
      "Epoch 141, Loss: 2.9558324813842773, Test Loss: 3.0687735080718994, \n",
      "Epoch 142, Loss: 2.958292245864868, Test Loss: 3.063851833343506, \n",
      "Epoch 143, Loss: 2.9555447101593018, Test Loss: 3.0633933544158936, \n",
      "Epoch 144, Loss: 2.9473304748535156, Test Loss: 3.060086488723755, \n",
      "Epoch 145, Loss: 2.9540114402770996, Test Loss: 3.0898396968841553, \n",
      "Epoch 146, Loss: 2.9520421028137207, Test Loss: 3.080916166305542, \n",
      "Epoch 147, Loss: 2.9491782188415527, Test Loss: 3.0585319995880127, \n",
      "Epoch 148, Loss: 2.950371742248535, Test Loss: 3.0606744289398193, \n",
      "Epoch 149, Loss: 2.9442451000213623, Test Loss: 3.0564396381378174, \n",
      "Epoch 150, Loss: 2.9460625648498535, Test Loss: 3.0553414821624756, \n",
      "Epoch 151, Loss: 2.9514122009277344, Test Loss: 3.0589420795440674, \n",
      "Epoch 152, Loss: 2.947948455810547, Test Loss: 3.072781801223755, \n",
      "Epoch 153, Loss: 2.949151039123535, Test Loss: 3.0638725757598877, \n",
      "Epoch 154, Loss: 2.9405298233032227, Test Loss: 3.057722568511963, \n",
      "Epoch 155, Loss: 2.9529542922973633, Test Loss: 3.057821273803711, \n",
      "Epoch 156, Loss: 2.9433646202087402, Test Loss: 3.054354429244995, \n",
      "Epoch 157, Loss: 2.9431545734405518, Test Loss: 3.072707414627075, \n",
      "Epoch 158, Loss: 2.9377639293670654, Test Loss: 3.0572259426116943, \n",
      "Epoch 159, Loss: 2.9526522159576416, Test Loss: 3.0512092113494873, \n",
      "Epoch 160, Loss: 2.934812307357788, Test Loss: 3.051351308822632, \n",
      "Epoch 161, Loss: 2.9281129837036133, Test Loss: 3.052661418914795, \n",
      "Epoch 162, Loss: 2.9341776371002197, Test Loss: 3.050808906555176, \n",
      "Epoch 163, Loss: 2.9309239387512207, Test Loss: 3.0535237789154053, \n",
      "Epoch 164, Loss: 2.928036689758301, Test Loss: 3.049927234649658, \n",
      "Epoch 165, Loss: 2.9433200359344482, Test Loss: 3.054123640060425, \n",
      "Epoch 166, Loss: 2.929152250289917, Test Loss: 3.0566563606262207, \n",
      "Epoch 167, Loss: 2.9272990226745605, Test Loss: 3.0498058795928955, \n",
      "Epoch 168, Loss: 2.936005115509033, Test Loss: 3.055277109146118, \n",
      "Epoch 169, Loss: 2.9254026412963867, Test Loss: 3.0488085746765137, \n",
      "Epoch 170, Loss: 2.93241286277771, Test Loss: 3.0513534545898438, \n",
      "Epoch 171, Loss: 2.929224967956543, Test Loss: 3.046560525894165, \n",
      "Epoch 172, Loss: 2.9287641048431396, Test Loss: 3.048609733581543, \n",
      "Epoch 173, Loss: 2.926039457321167, Test Loss: 3.045811891555786, \n",
      "Epoch 174, Loss: 2.9308221340179443, Test Loss: 3.0522243976593018, \n",
      "Epoch 175, Loss: 2.921511173248291, Test Loss: 3.047602653503418, \n",
      "Epoch 176, Loss: 2.9205307960510254, Test Loss: 3.0531158447265625, \n",
      "Epoch 177, Loss: 2.9239795207977295, Test Loss: 3.051565647125244, \n",
      "Epoch 178, Loss: 2.9169163703918457, Test Loss: 3.052382230758667, \n",
      "Epoch 179, Loss: 2.9241557121276855, Test Loss: 3.0426602363586426, \n",
      "Epoch 180, Loss: 2.9173922538757324, Test Loss: 3.0467522144317627, \n",
      "Epoch 181, Loss: 2.913240671157837, Test Loss: 3.0486927032470703, \n",
      "Epoch 182, Loss: 2.918111562728882, Test Loss: 3.054929733276367, \n",
      "Epoch 183, Loss: 2.9216978549957275, Test Loss: 3.041806697845459, \n",
      "Epoch 184, Loss: 2.9125707149505615, Test Loss: 3.0558018684387207, \n",
      "Epoch 185, Loss: 2.913555860519409, Test Loss: 3.0445148944854736, \n",
      "Epoch 186, Loss: 2.919299602508545, Test Loss: 3.0458602905273438, \n",
      "Epoch 187, Loss: 2.916368246078491, Test Loss: 3.0430378913879395, \n",
      "Epoch 188, Loss: 2.9090805053710938, Test Loss: 3.0624749660491943, \n",
      "Epoch 189, Loss: 2.9057154655456543, Test Loss: 3.0403199195861816, \n",
      "Epoch 190, Loss: 2.9127371311187744, Test Loss: 3.055331230163574, \n",
      "Epoch 191, Loss: 2.9107465744018555, Test Loss: 3.049874782562256, \n",
      "Epoch 192, Loss: 2.906982421875, Test Loss: 3.0410172939300537, \n",
      "Epoch 193, Loss: 2.908071279525757, Test Loss: 3.040674924850464, \n",
      "Epoch 194, Loss: 2.9075958728790283, Test Loss: 3.039379119873047, \n",
      "Epoch 195, Loss: 2.9124839305877686, Test Loss: 3.042135715484619, \n",
      "Epoch 196, Loss: 2.903897285461426, Test Loss: 3.039236545562744, \n",
      "Epoch 197, Loss: 2.907904624938965, Test Loss: 3.0411622524261475, \n",
      "Epoch 198, Loss: 2.9043924808502197, Test Loss: 3.038721799850464, \n",
      "Epoch 199, Loss: 2.911176919937134, Test Loss: 3.0388402938842773, \n",
      "Epoch 200, Loss: 2.900259017944336, Test Loss: 3.039438009262085, \n",
      "Epoch 201, Loss: 2.8974111080169678, Test Loss: 3.042534828186035, \n",
      "Epoch 202, Loss: 2.8985159397125244, Test Loss: 3.035435199737549, \n",
      "Epoch 203, Loss: 2.902575969696045, Test Loss: 3.039916515350342, \n",
      "Epoch 204, Loss: 2.8970096111297607, Test Loss: 3.037662982940674, \n",
      "Epoch 205, Loss: 2.898139715194702, Test Loss: 3.0381829738616943, \n",
      "Epoch 206, Loss: 2.8956499099731445, Test Loss: 3.049302339553833, \n",
      "Epoch 207, Loss: 2.901202917098999, Test Loss: 3.0378916263580322, \n",
      "Epoch 208, Loss: 2.8990113735198975, Test Loss: 3.036172866821289, \n",
      "Epoch 209, Loss: 2.904184579849243, Test Loss: 3.0380656719207764, \n",
      "Epoch 210, Loss: 2.893160343170166, Test Loss: 3.0418546199798584, \n",
      "Epoch 211, Loss: 2.9046380519866943, Test Loss: 3.0365688800811768, \n",
      "Epoch 212, Loss: 2.8961949348449707, Test Loss: 3.03715181350708, \n",
      "Epoch 213, Loss: 2.888705253601074, Test Loss: 3.042801856994629, \n",
      "Epoch 214, Loss: 2.8928756713867188, Test Loss: 3.0343093872070312, \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params, perf \u001b[38;5;129;01min\u001b[39;00m train_ds:\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mevaluator_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params, perf \u001b[38;5;129;01min\u001b[39;00m test_ds:\n\u001b[1;32m     13\u001b[0m     evaluator_test_step(params, perf)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    test_loss.reset_states()\n",
    "\n",
    "    i = 0\n",
    "    for params, perf in train_ds:\n",
    "        evaluator_train_step(params, perf)\n",
    "\n",
    "    for params, perf in test_ds:\n",
    "        evaluator_test_step(params, perf)\n",
    "\n",
    "    print(\n",
    "        f'Epoch {epoch + 1}, '\n",
    "        f'Loss: {train_loss.result()}, '\n",
    "        f'Test Loss: {test_loss.result()}, '\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27df9ca1-40b4-4977-9b10-5a9e4eea7c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[50.345535]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(tf.reshape(canonical_parameters, shape=(1, 29)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb731421-97e1-492d-bce7-4c536846ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_parameters = tf.constant(\n",
    "    [25.276] * 17 + [16] * 12,\n",
    "    dtype=\"float32\"\n",
    ")\n",
    "canonical_parameters = tf.reshape(canonical_parameters, shape=(1, 29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cd8a4b9-cc73-4af4-976a-23777f6d8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_mult = tf.constant([45] * 17 + [8] * 12, dtype=\"float32\")\n",
    "trans_add = tf.constant([5] * 17 + [16] * 12, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69773652-4e44-4b07-86ff-9037c416cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizerNetwork(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layers = [\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        ]\n",
    "        self.output_layer = tf.keras.layers.Dense(29, activation=\"sigmoid\")\n",
    "        \n",
    "    def call(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        x *= trans_mult\n",
    "        x += trans_add\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e2d2939-9177-4bba-9a33-55a69c91ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = OptimizerNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30d5f240-7483-46bf-9b17-065a83277787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"optimizer_network_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            multiple                  3840      \n",
      "                                                                 \n",
      " dense_14 (Dense)            multiple                  16512     \n",
      "                                                                 \n",
      " dense_15 (Dense)            multiple                  8256      \n",
      "                                                                 \n",
      " dense_16 (Dense)            multiple                  2080      \n",
      "                                                                 \n",
      " dense_17 (Dense)            multiple                  957       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,645\n",
      "Trainable params: 31,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer.build(input_shape=(None, 29))\n",
    "optimizer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18fb9f61-d614-4726-a9ef-6f60d22445d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanAbsoluteError()\n",
    "nadam = tf.keras.optimizers.Nadam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c57e466-d412-4437-abaa-c42542133580",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82a77322-bb64-48fe-8893-a0886fab3d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def optimizer_train_step(params):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = optimizer(params, training=True)\n",
    "        evaluation = evaluator(predictions, training=False) / 100\n",
    "        loss = 1 - evaluation\n",
    "    gradients = tape.gradient(loss, optimizer.trainable_variables)\n",
    "    nadam.apply_gradients(zip(gradients, optimizer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e503949a-1085-4fe4-93fc-843ee597bb45",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4614155888557434, \n",
      "Epoch 2, Loss: 0.44052553176879883, \n",
      "Epoch 3, Loss: 0.43913179636001587, \n",
      "Epoch 4, Loss: 0.4166135787963867, \n",
      "Epoch 5, Loss: 0.44802194833755493, \n",
      "Epoch 6, Loss: 0.43418699502944946, \n",
      "Epoch 7, Loss: 0.43008875846862793, \n",
      "Epoch 8, Loss: 0.40896403789520264, \n",
      "Epoch 9, Loss: 0.4048801064491272, \n",
      "Epoch 10, Loss: 0.389570415019989, \n",
      "Epoch 11, Loss: 0.38671815395355225, \n",
      "Epoch 12, Loss: 0.3837262988090515, \n",
      "Epoch 13, Loss: 0.3738945722579956, \n",
      "Epoch 14, Loss: 0.3822762370109558, \n",
      "Epoch 15, Loss: 0.37402069568634033, \n",
      "Epoch 16, Loss: 0.37375110387802124, \n",
      "Epoch 17, Loss: 0.37267357110977173, \n",
      "Epoch 18, Loss: 0.3584631681442261, \n",
      "Epoch 19, Loss: 0.36900949478149414, \n",
      "Epoch 20, Loss: 0.3628655672073364, \n",
      "Epoch 21, Loss: 0.3595730662345886, \n",
      "Epoch 22, Loss: 0.36103934049606323, \n",
      "Epoch 23, Loss: 0.3448185324668884, \n",
      "Epoch 24, Loss: 0.35086071491241455, \n",
      "Epoch 25, Loss: 0.3470314145088196, \n",
      "Epoch 26, Loss: 0.34472817182540894, \n",
      "Epoch 27, Loss: 0.3455911874771118, \n",
      "Epoch 28, Loss: 0.3357498049736023, \n",
      "Epoch 29, Loss: 0.33829033374786377, \n",
      "Epoch 30, Loss: 0.33359336853027344, \n",
      "Epoch 31, Loss: 0.3298407793045044, \n",
      "Epoch 32, Loss: 0.3301788568496704, \n",
      "Epoch 33, Loss: 0.3261592984199524, \n",
      "Epoch 34, Loss: 0.3244876265525818, \n",
      "Epoch 35, Loss: 0.3222184181213379, \n",
      "Epoch 36, Loss: 0.3193361759185791, \n",
      "Epoch 37, Loss: 0.31812530755996704, \n",
      "Epoch 38, Loss: 0.3156737685203552, \n",
      "Epoch 39, Loss: 0.3136144280433655, \n",
      "Epoch 40, Loss: 0.3122907280921936, \n",
      "Epoch 41, Loss: 0.3101842403411865, \n",
      "Epoch 42, Loss: 0.30889201164245605, \n",
      "Epoch 43, Loss: 0.30716216564178467, \n",
      "Epoch 44, Loss: 0.3053004741668701, \n",
      "Epoch 45, Loss: 0.3034043312072754, \n",
      "Epoch 46, Loss: 0.3013836145401001, \n",
      "Epoch 47, Loss: 0.29932552576065063, \n",
      "Epoch 48, Loss: 0.29701173305511475, \n",
      "Epoch 49, Loss: 0.2951406240463257, \n",
      "Epoch 50, Loss: 0.29359692335128784, \n",
      "Epoch 51, Loss: 0.2919068932533264, \n",
      "Epoch 52, Loss: 0.29036861658096313, \n",
      "Epoch 53, Loss: 0.28912121057510376, \n",
      "Epoch 54, Loss: 0.28764671087265015, \n",
      "Epoch 55, Loss: 0.2865869998931885, \n",
      "Epoch 56, Loss: 0.28535938262939453, \n",
      "Epoch 57, Loss: 0.28412944078445435, \n",
      "Epoch 58, Loss: 0.28296273946762085, \n",
      "Epoch 59, Loss: 0.2818400263786316, \n",
      "Epoch 60, Loss: 0.2807798981666565, \n",
      "Epoch 61, Loss: 0.27971261739730835, \n",
      "Epoch 62, Loss: 0.2787182927131653, \n",
      "Epoch 63, Loss: 0.27784234285354614, \n",
      "Epoch 64, Loss: 0.2767025828361511, \n",
      "Epoch 65, Loss: 0.2757241129875183, \n",
      "Epoch 66, Loss: 0.27481609582901, \n",
      "Epoch 67, Loss: 0.27397990226745605, \n",
      "Epoch 68, Loss: 0.27312171459198, \n",
      "Epoch 69, Loss: 0.2722512483596802, \n",
      "Epoch 70, Loss: 0.2716100215911865, \n",
      "Epoch 71, Loss: 0.27074646949768066, \n",
      "Epoch 72, Loss: 0.2699957489967346, \n",
      "Epoch 73, Loss: 0.26940852403640747, \n",
      "Epoch 74, Loss: 0.2687234878540039, \n",
      "Epoch 75, Loss: 0.2679644823074341, \n",
      "Epoch 76, Loss: 0.26728999614715576, \n",
      "Epoch 77, Loss: 0.2664632797241211, \n",
      "Epoch 78, Loss: 0.2657797932624817, \n",
      "Epoch 79, Loss: 0.26515161991119385, \n",
      "Epoch 80, Loss: 0.26448845863342285, \n",
      "Epoch 81, Loss: 0.2638514041900635, \n",
      "Epoch 82, Loss: 0.26323777437210083, \n",
      "Epoch 83, Loss: 0.2626822590827942, \n",
      "Epoch 84, Loss: 0.26203662157058716, \n",
      "Epoch 85, Loss: 0.26148462295532227, \n",
      "Epoch 86, Loss: 0.26100802421569824, \n",
      "Epoch 87, Loss: 0.2604672908782959, \n",
      "Epoch 88, Loss: 0.2599475383758545, \n",
      "Epoch 89, Loss: 0.25942420959472656, \n",
      "Epoch 90, Loss: 0.25894850492477417, \n",
      "Epoch 91, Loss: 0.2585916519165039, \n",
      "Epoch 92, Loss: 0.25810515880584717, \n",
      "Epoch 93, Loss: 0.25770342350006104, \n",
      "Epoch 94, Loss: 0.25738322734832764, \n",
      "Epoch 95, Loss: 0.2570495009422302, \n",
      "Epoch 96, Loss: 0.2567923665046692, \n",
      "Epoch 97, Loss: 0.25649237632751465, \n",
      "Epoch 98, Loss: 0.2560955286026001, \n",
      "Epoch 99, Loss: 0.25574469566345215, \n",
      "Epoch 100, Loss: 0.2555108070373535, \n",
      "Epoch 101, Loss: 0.255248486995697, \n",
      "Epoch 102, Loss: 0.2550010681152344, \n",
      "Epoch 103, Loss: 0.25471019744873047, \n",
      "Epoch 104, Loss: 0.2544317841529846, \n",
      "Epoch 105, Loss: 0.2542763948440552, \n",
      "Epoch 106, Loss: 0.25401270389556885, \n",
      "Epoch 107, Loss: 0.2537496089935303, \n",
      "Epoch 108, Loss: 0.2535465359687805, \n",
      "Epoch 109, Loss: 0.2532949447631836, \n",
      "Epoch 110, Loss: 0.2531614303588867, \n",
      "Epoch 111, Loss: 0.25297343730926514, \n",
      "Epoch 112, Loss: 0.25269967317581177, \n",
      "Epoch 113, Loss: 0.25261837244033813, \n",
      "Epoch 114, Loss: 0.2524182200431824, \n",
      "Epoch 115, Loss: 0.2521365284919739, \n",
      "Epoch 116, Loss: 0.252096951007843, \n",
      "Epoch 117, Loss: 0.2519146203994751, \n",
      "Epoch 118, Loss: 0.2517423629760742, \n",
      "Epoch 119, Loss: 0.25160807371139526, \n",
      "Epoch 120, Loss: 0.251476526260376, \n",
      "Epoch 121, Loss: 0.2512935996055603, \n",
      "Epoch 122, Loss: 0.251224160194397, \n",
      "Epoch 123, Loss: 0.25099390745162964, \n",
      "Epoch 124, Loss: 0.2509394884109497, \n",
      "Epoch 125, Loss: 0.25077956914901733, \n",
      "Epoch 126, Loss: 0.25069481134414673, \n",
      "Epoch 127, Loss: 0.2506062984466553, \n",
      "Epoch 128, Loss: 0.25040721893310547, \n",
      "Epoch 129, Loss: 0.2503253221511841, \n",
      "Epoch 130, Loss: 0.2502514719963074, \n",
      "Epoch 131, Loss: 0.25011712312698364, \n",
      "Epoch 132, Loss: 0.25002145767211914, \n",
      "Epoch 133, Loss: 0.2499217987060547, \n",
      "Epoch 134, Loss: 0.2498253583908081, \n",
      "Epoch 135, Loss: 0.24975883960723877, \n",
      "Epoch 136, Loss: 0.24963432550430298, \n",
      "Epoch 137, Loss: 0.24958384037017822, \n",
      "Epoch 138, Loss: 0.2494860291481018, \n",
      "Epoch 139, Loss: 0.24946260452270508, \n",
      "Epoch 140, Loss: 0.24929112195968628, \n",
      "Epoch 141, Loss: 0.24926239252090454, \n",
      "Epoch 142, Loss: 0.24919748306274414, \n",
      "Epoch 143, Loss: 0.24920707941055298, \n",
      "Epoch 144, Loss: 0.2491198182106018, \n",
      "Epoch 145, Loss: 0.2490672469139099, \n",
      "Epoch 146, Loss: 0.24898940324783325, \n",
      "Epoch 147, Loss: 0.2489585280418396, \n",
      "Epoch 148, Loss: 0.24892204999923706, \n",
      "Epoch 149, Loss: 0.24886256456375122, \n",
      "Epoch 150, Loss: 0.24886351823806763, \n",
      "Epoch 151, Loss: 0.24871957302093506, \n",
      "Epoch 152, Loss: 0.248670756816864, \n",
      "Epoch 153, Loss: 0.24867743253707886, \n",
      "Epoch 154, Loss: 0.24862635135650635, \n",
      "Epoch 155, Loss: 0.24864917993545532, \n",
      "Epoch 156, Loss: 0.248601496219635, \n",
      "Epoch 157, Loss: 0.2485593557357788, \n",
      "Epoch 158, Loss: 0.24851757287979126, \n",
      "Epoch 159, Loss: 0.24844062328338623, \n",
      "Epoch 160, Loss: 0.24843817949295044, \n",
      "Epoch 161, Loss: 0.24838298559188843, \n",
      "Epoch 162, Loss: 0.24837297201156616, \n",
      "Epoch 163, Loss: 0.2483333945274353, \n",
      "Epoch 164, Loss: 0.2482888102531433, \n",
      "Epoch 165, Loss: 0.24827539920806885, \n",
      "Epoch 166, Loss: 0.24827075004577637, \n",
      "Epoch 167, Loss: 0.24824106693267822, \n",
      "Epoch 168, Loss: 0.24826759099960327, \n",
      "Epoch 169, Loss: 0.2481803297996521, \n",
      "Epoch 170, Loss: 0.24818521738052368, \n",
      "Epoch 171, Loss: 0.24812203645706177, \n",
      "Epoch 172, Loss: 0.2480950951576233, \n",
      "Epoch 173, Loss: 0.2480500340461731, \n",
      "Epoch 174, Loss: 0.2479865550994873, \n",
      "Epoch 175, Loss: 0.24801170825958252, \n",
      "Epoch 176, Loss: 0.24805980920791626, \n",
      "Epoch 177, Loss: 0.24800467491149902, \n",
      "Epoch 178, Loss: 0.24801796674728394, \n",
      "Epoch 179, Loss: 0.2479778528213501, \n",
      "Epoch 180, Loss: 0.24794989824295044, \n",
      "Epoch 181, Loss: 0.24796181917190552, \n",
      "Epoch 182, Loss: 0.2479625940322876, \n",
      "Epoch 183, Loss: 0.24790549278259277, \n",
      "Epoch 184, Loss: 0.2478724718093872, \n",
      "Epoch 185, Loss: 0.24786388874053955, \n",
      "Epoch 186, Loss: 0.24782311916351318, \n",
      "Epoch 187, Loss: 0.24785691499710083, \n",
      "Epoch 188, Loss: 0.24781906604766846, \n",
      "Epoch 189, Loss: 0.2477385401725769, \n",
      "Epoch 190, Loss: 0.24771934747695923, \n",
      "Epoch 191, Loss: 0.24769359827041626, \n",
      "Epoch 192, Loss: 0.2476937174797058, \n",
      "Epoch 193, Loss: 0.24767982959747314, \n",
      "Epoch 194, Loss: 0.24767595529556274, \n",
      "Epoch 195, Loss: 0.24765533208847046, \n",
      "Epoch 196, Loss: 0.24764031171798706, \n",
      "Epoch 197, Loss: 0.2475852370262146, \n",
      "Epoch 198, Loss: 0.24761193990707397, \n",
      "Epoch 199, Loss: 0.24752891063690186, \n",
      "Epoch 200, Loss: 0.24748164415359497, \n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "possible_densities = tf.random.uniform((1, 17), minval=5, maxval=50, dtype=\"float32\", seed=42)\n",
    "params = tf.random.uniform((1, 12), minval=16, maxval=24, dtype=\"float32\", seed=42)\n",
    "params = tf.concat([possible_densities, params], axis=1)\n",
    "\n",
    "params = tf.reshape(params, shape=(1, 29))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    params = optimizer_train_step(params)\n",
    "\n",
    "    print(\n",
    "        f'Epoch {epoch + 1}, '\n",
    "        f'Loss: {train_loss.result()}, '\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d315d2ed-405b-4cca-b1ce-8affb2608daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 29), dtype=float32, numpy=\n",
       "array([[49.999996 , 49.99993  ,  6.0733767,  5.057633 ,  5.0000215,\n",
       "         5.0015955,  5.1109986,  5.136513 ,  5.0182495,  5.057583 ,\n",
       "         5.551576 ,  5.332079 ,  5.012101 ,  5.053944 , 49.99966  ,\n",
       "         5.018517 , 49.999924 , 16.004532 , 23.99833  , 23.999153 ,\n",
       "        23.159641 , 16.000074 , 23.874561 , 24.       , 16.029768 ,\n",
       "        16.027681 , 16.055325 , 23.999912 , 23.999594 ]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33ecfcef-8a9e-44dc-ac93-c45883be00e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       " array([[0.01566267],\n",
       "        [0.06093216]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.9720097>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "calculate_center_of_mass(tf.reshape(params, (29,)), show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b4336892-d8af-4e7b-aabf-7a110ae49063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.76106596>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.linspace(0, 120, 1000)\n",
    "evaluate_efficiency(tf.reshape(params, (29,)), t, show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f114353-0282-449e-9cd9-7b2d0f68961a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5056526>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_efficiency(tf.reshape(canonical_parameters, (29,)), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0aa71fee-3723-413c-bc6f-1ccb0803cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tf.concat([tf.reshape(params, (29,)), tf.constant([0.76106596])], axis=0).numpy()\n",
    "d = tf.reshape(d, shape=(30, 1))\n",
    "bdf = pd.DataFrame(d)\n",
    "bdf.to_csv(\"best_params.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4583ba-77f7-469d-8a5d-ba4fba02f2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
